{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG & Prompt Engineering with gtext\n",
    "\n",
    "**Learn how to use gtext to create composable, dynamic prompts for AI/LLM applications.**\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Build reusable prompt templates\n",
    "- Include dynamic context (git diffs, recent commits, code files)\n",
    "- Create RAG pipelines with versioned prompts\n",
    "- Integrate with LLM APIs (OpenAI, Anthropic, etc.)\n",
    "\n",
    "## Why gtext for RAG?\n",
    "\n",
    "gtext is like a **weaverbird** ü™∂ - it weaves together different pieces of content to create a unified whole:\n",
    "\n",
    "- **Composable**: Break prompts into reusable components\n",
    "- **Dynamic**: Always include latest context (code, data, etc.)\n",
    "- **Versionable**: Track prompt changes in git\n",
    "- **Traceable**: Know exactly what context was used\n",
    "- **Reproducible**: Same prompt + same context = same result\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install gtext\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install gtext and create a sample project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gtext\n",
    "!pip install -q gtext\n",
    "\n",
    "# Create demo project structure\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('demo_project/prompts', exist_ok=True)\n",
    "os.makedirs('demo_project/context', exist_ok=True)\n",
    "os.makedirs('demo_project/src', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Demo project structure created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Prompt Template\n",
    "\n",
    "Let's create a simple code review prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/prompts/code-review.md.gtext\n",
    "# Code Review Request\n",
    "\n",
    "You are an expert code reviewer. Please review the following code changes.\n",
    "\n",
    "## Changes to Review\n",
    "\n",
    "```include\n",
    "cli: git diff --cached\n",
    "```\n",
    "\n",
    "## Review Criteria\n",
    "\n",
    "Please evaluate:\n",
    "1. **Code Quality**: Is the code clean, readable, and maintainable?\n",
    "2. **Best Practices**: Does it follow language/framework best practices?\n",
    "3. **Security**: Are there any security vulnerabilities?\n",
    "4. **Performance**: Any performance concerns?\n",
    "5. **Testing**: Is the code testable?\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Provide:\n",
    "- Overall assessment (approve/request changes)\n",
    "- Specific issues found (with line numbers)\n",
    "- Suggestions for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create some sample code to review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/src/calculator.py\n",
    "def calculate(a, b, operation):\n",
    "    \"\"\"Perform calculation on two numbers.\"\"\"\n",
    "    if operation == 'add':\n",
    "        return a + b\n",
    "    elif operation == 'subtract':\n",
    "        return a - b\n",
    "    elif operation == 'multiply':\n",
    "        return a * b\n",
    "    elif operation == 'divide':\n",
    "        return a / b  # Potential division by zero!\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown operation: {operation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage the file and generate the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize git repo (if not already done)\n",
    "!cd demo_project && git init 2>/dev/null || true\n",
    "!cd demo_project && git config user.email \"demo@example.com\" 2>/dev/null || true\n",
    "!cd demo_project && git config user.name \"Demo User\" 2>/dev/null || true\n",
    "\n",
    "# Stage the file\n",
    "!cd demo_project && git add src/calculator.py\n",
    "\n",
    "# Generate the prompt using gtext\n",
    "!cd demo_project && gtext cast prompts/code-review.md.gtext\n",
    "\n",
    "print(\"\\n‚úÖ Prompt generated! Check demo_project/prompts/code-review.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the generated prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('demo_project/prompts/code-review.md', 'r') as f:\n",
    "    prompt = f.read()\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Composable Prompt Components\n",
    "\n",
    "Real-world prompts often share common sections. Let's create reusable components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/context/project-info.md\n",
    "## Project Context\n",
    "\n",
    "**Project**: Demo Calculator\n",
    "**Language**: Python 3.9+\n",
    "**Style Guide**: PEP 8\n",
    "**Testing**: pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/context/recent-commits.md.gtext\n",
    "## Recent Commits\n",
    "\n",
    "```include\n",
    "cli: git log --oneline -5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/prompts/enhanced-review.md.gtext\n",
    "# Enhanced Code Review\n",
    "\n",
    "```include\n",
    "static: context/project-info.md\n",
    "```\n",
    "\n",
    "```include\n",
    ":expand:static: context/recent-commits.md.gtext\n",
    "```\n",
    "\n",
    "## Changes Under Review\n",
    "\n",
    "```include\n",
    "cli: git diff --cached\n",
    "```\n",
    "\n",
    "## Review Task\n",
    "\n",
    "Please review these changes with the project context in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `:expand:` modifier - it tells gtext to recursively process the included file, expanding the `git log` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate enhanced prompt\n",
    "!cd demo_project && gtext cast prompts/enhanced-review.md.gtext\n",
    "\n",
    "# View result\n",
    "with open('demo_project/prompts/enhanced-review.md', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: RAG Pipeline with Code Context\n",
    "\n",
    "Let's build a more sophisticated RAG prompt that includes:\n",
    "- Multiple source files\n",
    "- Test files\n",
    "- Documentation\n",
    "- Recent changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more files for context\n",
    "%%writefile demo_project/src/test_calculator.py\n",
    "import pytest\n",
    "from calculator import calculate\n",
    "\n",
    "def test_add():\n",
    "    assert calculate(2, 3, 'add') == 5\n",
    "\n",
    "def test_divide():\n",
    "    assert calculate(10, 2, 'divide') == 5\n",
    "    # Missing: test for division by zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/prompts/comprehensive-analysis.md.gtext\n",
    "# Comprehensive Code Analysis Request\n",
    "\n",
    "You are an AI assistant helping improve code quality.\n",
    "\n",
    "## Project Files\n",
    "\n",
    "### Source Code\n",
    "\n",
    "```include\n",
    "glob: src/*.py\n",
    "```\n",
    "\n",
    "## Recent Activity\n",
    "\n",
    "```include\n",
    "cli: git log --oneline --all -10\n",
    "```\n",
    "\n",
    "## Analysis Request\n",
    "\n",
    "Please analyze the code above and provide:\n",
    "\n",
    "1. **Test Coverage Gaps**: What's not being tested?\n",
    "2. **Potential Bugs**: Any edge cases or error conditions?\n",
    "3. **Refactoring Opportunities**: How could the code be improved?\n",
    "4. **Documentation Needs**: What should be documented better?\n",
    "\n",
    "Focus on actionable suggestions with specific examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive analysis prompt\n",
    "!cd demo_project && gtext cast prompts/comprehensive-analysis.md.gtext\n",
    "\n",
    "# View result\n",
    "with open('demo_project/prompts/comprehensive-analysis.md', 'r') as f:\n",
    "    prompt = f.read()\n",
    "    print(prompt)\n",
    "    print(f\"\\nüìä Prompt length: {len(prompt)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Integration with LLM APIs\n",
    "\n",
    "Now let's see how to integrate gtext-generated prompts with actual LLM APIs.\n",
    "\n",
    "**Note**: This example shows the pattern. You'll need your own API keys to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtext.processor import TextProcessor\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_prompt(template_path: str, output_path: str = None) -> str:\n",
    "    \"\"\"Generate prompt from gtext template.\n",
    "    \n",
    "    Args:\n",
    "        template_path: Path to .gtext template file\n",
    "        output_path: Optional path to save generated prompt\n",
    "        \n",
    "    Returns:\n",
    "        Generated prompt text\n",
    "    \"\"\"\n",
    "    processor = TextProcessor()\n",
    "    \n",
    "    # Process template\n",
    "    template_file = Path(template_path)\n",
    "    prompt = processor.process_file(template_file, output_path=output_path)\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Example: Generate prompt\n",
    "prompt = generate_prompt('demo_project/prompts/code-review.md.gtext')\n",
    "print(\"‚úÖ Prompt generated programmatically!\")\n",
    "print(f\"Length: {len(prompt)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration Pattern: OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example integration (requires openai package + API key)\n",
    "def send_to_openai(prompt_template: str, model: str = \"gpt-4\"):\n",
    "    \"\"\"Send gtext-generated prompt to OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        prompt_template: Path to .gtext template\n",
    "        model: OpenAI model to use\n",
    "        \n",
    "    Returns:\n",
    "        AI response\n",
    "    \"\"\"\n",
    "    # Generate fresh prompt with latest context\n",
    "    prompt = generate_prompt(prompt_template)\n",
    "    \n",
    "    # Send to OpenAI (pseudo-code)\n",
    "    # import openai\n",
    "    # response = openai.ChatCompletion.create(\n",
    "    #     model=model,\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"user\", \"content\": prompt}\n",
    "    #     ]\n",
    "    # )\n",
    "    # return response.choices[0].message.content\n",
    "    \n",
    "    return \"[AI response would appear here]\"\n",
    "\n",
    "print(\"Pattern demonstrated - add your API key to run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration Pattern: Anthropic Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_claude(prompt_template: str, model: str = \"claude-3-opus-20240229\"):\n",
    "    \"\"\"Send gtext-generated prompt to Anthropic Claude.\n",
    "    \n",
    "    Args:\n",
    "        prompt_template: Path to .gtext template\n",
    "        model: Claude model to use\n",
    "        \n",
    "    Returns:\n",
    "        AI response\n",
    "    \"\"\"\n",
    "    prompt = generate_prompt(prompt_template)\n",
    "    \n",
    "    # Send to Claude (pseudo-code)\n",
    "    # import anthropic\n",
    "    # client = anthropic.Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "    # message = client.messages.create(\n",
    "    #     model=model,\n",
    "    #     max_tokens=4096,\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"user\", \"content\": prompt}\n",
    "    #     ]\n",
    "    # )\n",
    "    # return message.content[0].text\n",
    "    \n",
    "    return \"[Claude response would appear here]\"\n",
    "\n",
    "print(\"Pattern demonstrated - add your API key to run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Advanced RAG Patterns\n",
    "\n",
    "### Pattern 1: Multi-Stage Prompts\n",
    "\n",
    "Break complex tasks into stages with separate prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/prompts/stage1-analyze.md.gtext\n",
    "# Stage 1: Code Analysis\n",
    "\n",
    "Analyze the following code and identify:\n",
    "1. Main functionality\n",
    "2. Dependencies\n",
    "3. Potential issues\n",
    "\n",
    "## Code\n",
    "\n",
    "```include\n",
    "glob: src/*.py\n",
    "```\n",
    "\n",
    "Provide a structured analysis in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/prompts/stage2-improve.md.gtext\n",
    "# Stage 2: Improvement Suggestions\n",
    "\n",
    "Based on this analysis:\n",
    "\n",
    "```include\n",
    "static: output/analysis-result.json\n",
    "```\n",
    "\n",
    "And the original code:\n",
    "\n",
    "```include\n",
    "glob: src/*.py\n",
    "```\n",
    "\n",
    "Provide specific code improvements with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Versioned Prompt Templates\n",
    "\n",
    "Track prompt evolution in git alongside code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit prompt templates\n",
    "!cd demo_project && git add prompts/ context/\n",
    "!cd demo_project && git commit -m \"Add prompt templates v1.0\" 2>/dev/null || echo \"Already committed\"\n",
    "\n",
    "print(\"\\n‚úÖ Prompt templates versioned in git!\")\n",
    "print(\"\\nBenefits:\")\n",
    "print(\"- Track what prompts generated what outputs\")\n",
    "print(\"- A/B test different prompt versions\")\n",
    "print(\"- Rollback to previous prompts if needed\")\n",
    "print(\"- Collaborate on prompt engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 3: Dynamic Context Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo_project/prompts/smart-context.md.gtext\n",
    "# Smart Context Selection\n",
    "\n",
    "## Recently Modified Files (Last 7 Days)\n",
    "\n",
    "```include\n",
    "cli: git diff --name-only HEAD~7..HEAD\n",
    "```\n",
    "\n",
    "## Active Branch Context\n",
    "\n",
    "```include\n",
    "cli: git log origin/main..HEAD --oneline\n",
    "```\n",
    "\n",
    "## Most Changed Files (Hot Spots)\n",
    "\n",
    "```include\n",
    "cli: git log --pretty=format: --name-only | sort | uniq -c | sort -rg | head -5\n",
    "```\n",
    "\n",
    "Use this context to provide targeted analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for RAG with gtext\n",
    "\n",
    "### 1. Organize Prompts by Purpose\n",
    "\n",
    "```\n",
    "prompts/\n",
    "‚îú‚îÄ‚îÄ code-review/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ basic-review.md.gtext\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ security-review.md.gtext\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ performance-review.md.gtext\n",
    "‚îú‚îÄ‚îÄ documentation/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ api-docs.md.gtext\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ readme-update.md.gtext\n",
    "‚îî‚îÄ‚îÄ refactoring/\n",
    "    ‚îú‚îÄ‚îÄ suggest-refactor.md.gtext\n",
    "    ‚îî‚îÄ‚îÄ extract-function.md.gtext\n",
    "```\n",
    "\n",
    "### 2. Create Reusable Context Components\n",
    "\n",
    "```\n",
    "context/\n",
    "‚îú‚îÄ‚îÄ project-info.md         # Static project metadata\n",
    "‚îú‚îÄ‚îÄ recent-commits.md.gtext # Dynamic git history\n",
    "‚îú‚îÄ‚îÄ code-standards.md       # Coding guidelines\n",
    "‚îî‚îÄ‚îÄ test-strategy.md        # Testing approach\n",
    "```\n",
    "\n",
    "### 3. Use `:expand:` for Nested Templates\n",
    "\n",
    "```markdown\n",
    "```include\n",
    ":expand:static: context/recent-commits.md.gtext\n",
    "```\n",
    "```\n",
    "\n",
    "This recursively processes ````include` blocks in the included file.\n",
    "\n",
    "### 4. Measure and Optimize\n",
    "\n",
    "- Track prompt token counts\n",
    "- Monitor LLM costs per prompt\n",
    "- A/B test different prompt structures\n",
    "- Version prompts alongside code\n",
    "\n",
    "### 5. Cache Generated Prompts When Appropriate\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "def cached_generate(template: str, cache_dir: str = '.prompt_cache'):\n",
    "    \"\"\"Generate prompt with caching based on template content.\"\"\"\n",
    "    template_content = Path(template).read_text()\n",
    "    cache_key = hashlib.md5(template_content.encode()).hexdigest()\n",
    "    cache_file = Path(cache_dir) / f\"{cache_key}.md\"\n",
    "    \n",
    "    if cache_file.exists():\n",
    "        return cache_file.read_text()\n",
    "    \n",
    "    # Generate fresh\n",
    "    prompt = generate_prompt(template)\n",
    "    \n",
    "    # Cache it\n",
    "    cache_file.parent.mkdir(exist_ok=True)\n",
    "    cache_file.write_text(prompt)\n",
    "    \n",
    "    return prompt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Use Cases\n",
    "\n",
    "### Use Case 1: Automated Code Review Bot\n",
    "\n",
    "```bash\n",
    "# In CI/CD pipeline\n",
    "git diff origin/main...HEAD > changes.diff\n",
    "gtext cast prompts/code-review.md.gtext\n",
    "curl -X POST https://api.openai.com/v1/chat/completions \\\n",
    "  -d @prompts/code-review.md\n",
    "```\n",
    "\n",
    "### Use Case 2: Documentation Generation\n",
    "\n",
    "```python\n",
    "# Generate API docs from code\n",
    "prompt = generate_prompt('prompts/generate-api-docs.md.gtext')\n",
    "docs = llm.generate(prompt)\n",
    "Path('docs/api.md').write_text(docs)\n",
    "```\n",
    "\n",
    "### Use Case 3: Changelog Generation\n",
    "\n",
    "```markdown\n",
    "# prompts/changelog.md.gtext\n",
    "\n",
    "Generate a changelog for these commits:\n",
    "\n",
    "```include\n",
    "cli: git log v1.0.0..HEAD --pretty=format:\"%h %s\"\n",
    "```\n",
    "\n",
    "Group by: feat, fix, docs, refactor, test\n",
    "```\n",
    "\n",
    "### Use Case 4: Test Generation\n",
    "\n",
    "```markdown\n",
    "# prompts/generate-tests.md.gtext\n",
    "\n",
    "Generate unit tests for:\n",
    "\n",
    "```include\n",
    "static: src/new_feature.py\n",
    "```\n",
    "\n",
    "Use pytest style, aim for 100% coverage.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned how to use gtext for RAG and prompt engineering:\n",
    "\n",
    "‚úÖ **Create composable prompt templates** that include dynamic content\n",
    "\n",
    "‚úÖ **Use protocol handlers** (`cli:`, `static:`, `glob:`) to gather context\n",
    "\n",
    "‚úÖ **Apply `:expand:` modifier** for nested template processing\n",
    "\n",
    "‚úÖ **Integrate with LLM APIs** (OpenAI, Anthropic, etc.)\n",
    "\n",
    "‚úÖ **Version prompts in git** for reproducibility\n",
    "\n",
    "‚úÖ **Build RAG pipelines** with reusable components\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore more protocol handlers in the [documentation](https://gtext.readthedocs.io/)\n",
    "- Check out [future protocols](https://gtext.readthedocs.io/en/latest/extensions/include.html#future-protocols-planned) (`storage:`, `app:`, `db:`)\n",
    "- Build your own custom extensions\n",
    "- Share your prompt templates on GitHub!\n",
    "\n",
    "## Resources\n",
    "\n",
    "- üìö [gtext Documentation](https://gtext.readthedocs.io/)\n",
    "- üêô [GitHub Repository](https://github.com/genropy/gtext)\n",
    "- ü™∂ Like a weaverbird, gtext weaves together your context into perfect prompts!\n",
    "\n",
    "---\n",
    "\n",
    "**Happy prompt engineering! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
